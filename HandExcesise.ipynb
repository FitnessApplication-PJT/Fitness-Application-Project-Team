{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI pose estimation using MediaPipe and Hand Excercise Counter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# This is the imports section,\n",
    "\n",
    "import tkinter\n",
    "import customtkinter                    \n",
    "import mediapipe as mp            \n",
    "import numpy as np                \n",
    "import math      \n",
    "from tkinter import *         \n",
    "mp_drawing = mp.solutions.drawing_utils    \n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter=0\n",
    "counter1=0\n",
    "state=None\n",
    "state1=None\n",
    "state_Leg=None\n",
    "\n",
    "\n",
    "def calculateanle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:  \n",
    "    #cap = cv2.VideoCapture('sidelyinglegliftvideo.mp4')    # Start capturing the video from the file \"sidelyinglegliftvideo.mp4\"\n",
    "     cap = cv2.VideoCapture(0)                            # Alternatively, we can capture the video from the webcam (0)\n",
    " \n",
    "     while cap.isOpened():              \n",
    "        ret, frame = cap.read()         \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)   # Convert the image to RGB\n",
    "        results = holistic.process(image)    # Make a detection using the Holistic model on the image\n",
    "        annotated_image = image.copy()       # Make a copy of the image to draw landmarks on\n",
    "        annotated_image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks=results.pose_landmarks.landmark\n",
    "            #Get Cordinates.\n",
    "            import mediapipe as mp  # Make sure you import the module as \"mp\"\n",
    "\n",
    "# Assuming you have a \"landmarks\" variable\n",
    "        \n",
    "            \n",
    "             ## Iam Using this for Hand Excercise Detection,\n",
    "\n",
    "            top_hand=[landmarks[mp.pose_PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].z]\n",
    "           \n",
    "            mid_hand=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "            end_hand=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].ylandmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z]\n",
    "              \n",
    "            #---------------------------------   LEFT HAND SIDEWARD AND FORWARD.\n",
    "\n",
    "            top=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z]  # first \n",
    "            mid=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "\n",
    "            end=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z]\n",
    "             \n",
    "            angle=calculateanle(top_hand,mid_hand,end_hand)\n",
    "            \n",
    "\n",
    "            # if angle<=15:\n",
    "            #     if state_Leg==\"side\":\n",
    "            #         counter+=1\n",
    "            #     elif state_Leg==None:\n",
    "            #         state_Leg=\"front\"\n",
    "            # elif angle>=30:\n",
    "\n",
    "            #     if state_Leg==\"front\":\n",
    "            #         state_Leg=\"side\"\n",
    "            #     elif state_Leg==None:\n",
    "            #         state_Leg=\"side\"\n",
    "\n",
    "\n",
    "            #=--------------------------------------------------------------\n",
    "\n",
    "            # Left Leg Detection.\n",
    "\n",
    "            # top_leg=[landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # mid_leg=[landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            \n",
    "            # end_leg=[landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            #Find Angle.\n",
    "            angle=calculateanle(top_hand,mid_hand,end_hand)\n",
    "           # angle2=calculateanle(top_leg,mid_leg,end_leg)\n",
    "\n",
    "            #cv2.putText(image,str(angle),tuple(np.multiply(mid,[640,480])).astype(int),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),cv2.LINE_AAA)\n",
    "           \n",
    "            if angle<=90:\n",
    "                if state==\"down\":\n",
    "                    counter+=1\n",
    "                    state=\"up\"\n",
    "                elif state==None:\n",
    "                    state=\"up\"\n",
    "            else:\n",
    "                if state==\"up\":\n",
    "                    state=\"down\"\n",
    "                elif state==None:\n",
    "                    state=\"down\"\n",
    "\n",
    "\n",
    "\n",
    "                # if angle2<=90:\n",
    "                #     if state1==\"down\":\n",
    "                #         counter1+=1\n",
    "                #         state1=\"up\"\n",
    "                #     elif state1==None:\n",
    "                #         state1=\"up\"\n",
    "                # else:\n",
    "                #     if state1==\"up\":\n",
    "                #         state1=\"down\"\n",
    "                #     elif state1==None:\n",
    "                #         state1=\"down\"\n",
    "            \n",
    "\n",
    "        \n",
    "            cv2.rectangle(annotated_image,(0,0),(500,255),(245,117,16),-1)\n",
    "\n",
    "\n",
    "            cv2.putText(annotated_image, str(angle), (20, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)  # Prints the Angle on  the screen.\n",
    "\n",
    "            cv2.putText(annotated_image, \"Side Counter:\"+str(counter), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            #cv2.putText(annotated_image, \"My Angele:\"+str(angle), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                  \n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66),thickness=4,circle_radius=5),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230),thickness=4,circle_radius=4)\n",
    "                                  \n",
    "                                  )   # Draw the detected landmarks on the image\n",
    "\n",
    "        \n",
    "\n",
    "        cv2.imshow('MediaPipe Holistic', annotated_image)\n",
    "       \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.278691136407753\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "len(landmarks)\n",
    "\n",
    "# for lndmrk in mp_pose.PoseLandmark:\n",
    "#     print(lndmrk)\n",
    "\n",
    "top=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].z]  # first \n",
    "mid=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].z]\n",
    "\n",
    "end=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].z]\n",
    "angle=calculateanle(top,mid,end)\n",
    "print(angle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'click' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Codeforces\\HandExcesise.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Codeforces/HandExcesise.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Show image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Codeforces/HandExcesise.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Codeforces/HandExcesise.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m cv2\u001b[39m.\u001b[39msetMouseCallback(\u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m, click) \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Codeforces/HandExcesise.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclick\u001b[39m(event, x, y, flags, param):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Codeforces/HandExcesise.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m   \u001b[39mif\u001b[39;00m event \u001b[39m==\u001b[39m cv2\u001b[39m.\u001b[39mEVENT_LBUTTONDOWN:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'click' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a black image\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "# Create buttons\n",
    "btn1 = np.zeros((100,200,3)) \n",
    "btn2 = np.zeros((100,200,3))\n",
    "\n",
    "# Add text to buttons\n",
    "cv2.putText(btn1, 'Button 1', (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "cv2.putText(btn2, 'Button 2', (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "# Define button positions\n",
    "x1, y1, w1, h1 = 100, 100, 100, 50 \n",
    "x2, y2, w2, h2 = 300, 100, 100, 50\n",
    "\n",
    "# Draw buttons on image\n",
    "btn1 = cv2.resize(btn1, (w1, h1)) \n",
    "btn2 = cv2.resize(btn2, (w2, h2))\n",
    "\n",
    "# Now draw buttons on image\n",
    "img[y1:y1+h1, x1:x1+w1] = btn1  \n",
    "img[y2:y2+h2, x2:x2+w2] = btn2\n",
    "img[y1:y1+h1, x1:x1+w1] = btn1\n",
    "img[y2:y2+h2, x2:x2+w2] = btn2\n",
    "\n",
    "# Show image\n",
    "cv2.imshow('Image', img)\n",
    "cv2.setMouseCallback('Image', click) \n",
    "\n",
    "def click(event, x, y, flags, param):\n",
    "  if event == cv2.EVENT_LBUTTONDOWN:\n",
    "    if x1 < x < x1+w1 and y1 < y < y1+h1:\n",
    "      print(\"Button 1 clicked\")\n",
    "    if x2 < x < x2+w2 and y2 < y < y2+h2:\n",
    "      print(\"Button 2 clicked\")\n",
    "      \n",
    "# Keep window open until key press  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
